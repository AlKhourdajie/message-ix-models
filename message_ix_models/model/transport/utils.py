from contextlib import contextmanager
from collections import ChainMap, defaultdict
from itertools import product
import logging.config
from pathlib import Path

import yaml
import pandas as pd
import xarray as xr


# Path to the directory containing data & metadata files
data_path = Path(__file__).resolve().parents[3] / 'data' / 'transport'


# Configuration dictionary
config = {}


def read_config():
    """Read the transport model configuration from file."""
    global config

    def yaml_data(*parts):
        """Open a YAML file in the (meta)data directory and return contents."""
        with open(data_path.joinpath(*parts).with_suffix('.yaml')) as f:
            return yaml.safe_load(f)

    config = {
        # Storage for exogenous data
        'data': xr.Dataset(),

        # Information about the MESSAGE V model
        'MESSAGE V': {
            'set': yaml_data('migrate', 'set'),
            },

        # Information about the MESSAGEix framework
        'param': yaml_data('..', 'parameter'),

        # Information about MESSAGE-Transport
        'model': yaml_data('config'),
        'set': yaml_data('set'),
        'tech': yaml_data('technology'),
        }

    # Callback information
    cb_cfg = yaml_data('callback')

    # Convert files to xr.DataArrays
    for key, dims in cb_cfg.pop('files').items():
        config['data'][key] = xr.DataArray.from_series(
            pd.read_csv(data_path / f'{key}.csv', index_col=0)
            .rename_axis(dims[1], axis=1)
            .stack())

    # Convert scalar parameters
    for key, val in cb_cfg.pop('params').items():
        config['data'][key] = val

    # Configure logging
    with open(Path(__file__).parent / 'logging.yaml') as f:
        logging.config.dictConfig(yaml.safe_load(f))


# commented to enable RTD build
# TODO automatically read configuration given a Context object
# read_config()


def consumer_groups(with_desc=False):
    """Iterate over consumer groups in ``sets.yaml``."""
    dims = ['location', 'attitude', 'frequency']
    cfg = config['set']['consumer groups']

    # Assemble technology names
    keys = [cfg[d].keys() for d in dims]
    name = [''.join(k) for k in product(*keys)]

    if with_desc:
        # Assemble technology descriptions
        vals = [cfg[d].values() for d in dims]
        desc = [', '.join(v).lower() for v in product(*vals)]

        yield from sorted(zip(name, desc))
    else:
        yield from sorted(name)


def make_df(par_name, tech=None, **kwargs):
    """Return an empty dataframe for *par_name*, *tech*."""
    cols = config['param'][par_name] + ['value', 'unit']
    data = {}
    try:
        tec_info = config['tech']['technology'][tech]['par'][par_name]
        tec_info['technology'] = tech
    except KeyError:
        tec_info = {}

    data = ChainMap(kwargs, tec_info, defaultdict(lambda: None))
    data = {c: data[c] for c in cols}

    return pd.DataFrame.from_dict(data, orient='columns')


def iter_parameters(set_name):
    """Iterate over MESSAGEix parameters with *set_name* as a dimension."""
    for name, dims in config['param'].items():
        if set_name in dims:
            yield name


def transport_technologies(by_cg=True, filter=[], with_desc=False):
    """Iterate over transport technologies in ``messagev-tech.yaml``.

    Technologies listed with `by_consumer_group` = :obj:`True` are returned
    once for each consumer group generated by :meth:`consumer_groups`.
    """
    for tech, info in config['tech']['technology'].items():
        if len(filter) and tech not in filter:
            continue

        if by_cg and info.get('by_consumer_group', False):
            if with_desc:
                for name, desc in consumer_groups(with_desc=True):
                    yield f'{tech}_{name}', \
                        f"{info['description']} ({desc})"
            else:
                yield from [f'{tech}_{cg}' for cg in consumer_groups()]
        else:
            yield (tech, info.get('description', '')) if with_desc else tech


@contextmanager
def silence_log():
    """Context manager to temporarily silence log output."""
    # Get the main logger
    main_log = logging.getLogger('.'.join(__name__.split('.')[:-1]))

    try:
        main_log.setLevel(100)
        yield
    finally:
        main_log.setLevel(logging.INFO)
